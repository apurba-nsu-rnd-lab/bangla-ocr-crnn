{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a custom dataset for BNHTRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/word_level_ocr/pritom/notebooks'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from contextlib import suppress\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNHTRD_DATASET = \"/home/ec2-user/word_level_ocr/pritom/datasets/handwriting/BN-HTRd/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnhtrd_words_path = []\n",
    "\n",
    "for file in glob.glob(BNHTRD_DATASET+\"Dataset/*/Words/*/*.[jJ|pP][pP|nN][gG]\"):\n",
    "    bnhtrd_words_path.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bnhtrd_words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_1_10_1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(bnhtrd_words_path[0]).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnhtrd_word_to_path_dict = {}\n",
    "\n",
    "for path in bnhtrd_words_path:\n",
    "    bnhtrd_word_to_path_dict[Path(path).stem] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bnhtrd_word_to_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_subdirs = os.listdir(BNHTRD_DATASET+\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder  |  Images | Labels\n",
      "Writer 101 : 916 919\n",
      "Writer 114 : 387 386\n",
      "Writer 17 : 793 0\n",
      "Writer 30 : 1357 1355\n",
      "Writer 34 : 1422 746\n"
     ]
    }
   ],
   "source": [
    "print(\"Folder  |  Images | Labels\")\n",
    "\n",
    "for di in first_subdirs:\n",
    "    files = []\n",
    "    for file in glob.glob(BNHTRD_DATASET+\"/Dataset/\"+di+\"/Words/*/*.[jJ|pP][pP|nN][gG]\"):\n",
    "        files.append(file)\n",
    "            \n",
    "    ann_file = glob.glob(BNHTRD_DATASET+\"/Dataset/\"+di+\"*/*.xlsx\")\n",
    "    try:\n",
    "        df = pd.read_excel(list(ann_file)[0])\n",
    "    except ValueError:\n",
    "        with suppress(ValueError):\n",
    "            df = pd.read_excel(list(ann_file)[0])\n",
    "    \n",
    "    if len(files) != len(df):\n",
    "        print(\"Writer\", di, \":\", len(files), len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for ann_file in glob.glob(BNHTRD_DATASET+\"*/*.xlsx\"):\n",
    "    df = pd.read_excel(ann_file)\n",
    "    \n",
    "    total+=len(df)\n",
    "    \n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109_1_1_1</td>\n",
       "      <td>করোনা</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109_1_1_2</td>\n",
       "      <td>ভাইরাস</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109_1_1_3</td>\n",
       "      <td>আপডেট</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109_1_1_4</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109_1_1_5</td>\n",
       "      <td>ম্যাপ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id    Word\n",
       "0  109_1_1_1   করোনা\n",
       "1  109_1_1_2  ভাইরাস\n",
       "2  109_1_1_3   আপডেট\n",
       "3  109_1_1_4       :\n",
       "4  109_1_1_5   ম্যাপ"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder  |  Images | Labels\n",
      "Total Images, Labels: 108147 108147\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "BNHTRD_DATASET = \"/home/ec2-user/word_level_ocr/sabbir/datasets/BN-HTRd/\"\n",
    "\n",
    "total_labels = 0\n",
    "total_files = 0\n",
    "    \n",
    "print(\"Folder  |  Images | Labels\")\n",
    "\n",
    "first_subdirs = os.listdir(BNHTRD_DATASET)\n",
    "\n",
    "for di in first_subdirs:\n",
    "    files = []\n",
    "    for file in glob.glob(BNHTRD_DATASET+\"/\"+di+\"/Words/*/*.[jJ|pP][pP|nN][gG]\"):\n",
    "        files.append(file)\n",
    "        \n",
    "    ann_file = glob.glob(BNHTRD_DATASET+\"/\"+di+\"/*.xlsx\")\n",
    "    \n",
    "    if di == \"17\":\n",
    "        # 17.xlsx mistakenly has two sheets, and we need to specify which one to open\n",
    "        df = pd.read_excel(list(ann_file)[0], sheet_name=\"Sheet1\")\n",
    "    else:\n",
    "        df = pd.read_excel(list(ann_file)[0])\n",
    "     \n",
    "    if di==\"101\":\n",
    "        # 101.xlsx has some trailing Nan value rows\n",
    "        df = df[df['Id'].notna()]\n",
    "    elif di==\"60\":\n",
    "        df = df.rename(columns={'ID': 'Id', 'word': 'Word'})\n",
    "    elif di==\"30\":\n",
    "        # Add missing labels\n",
    "        df.loc[len(df.index)] = ['30_6_2_3 (1)', 'নির্ধারকরা'] \n",
    "        df.loc[len(df.index)] = ['30_6_2_4 (1)', 'বোঝান'] \n",
    "        # Edit duplicate label\n",
    "        df.loc[905] = ['30_6_6_7', 'এশিয়ায়'] \n",
    "    elif di==\"114\":\n",
    "        # Edit duplicate label\n",
    "        df.loc[905] = ['30_6_6_7', 'দেখা'] \n",
    "        \n",
    "    \n",
    "    total_labels += df.shape[0]\n",
    "    total_files += len(files)\n",
    "    \n",
    "    if len(files) != df.shape[0]:\n",
    "        print(\"Writer\", di, \":\", len(files), df.shape[0])\n",
    "\n",
    "print(\"Total Images, Labels:\", total_files, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'114_1_3_2', '114_1_8_7'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "test = 114\n",
    "\n",
    "df_test = pd.read_excel(BNHTRD_DATASET+\"/\"+str(test)+\"/\"+str(test)+\".xlsx\", index=False)\n",
    "\n",
    "label_names = set(df_test.Id)\n",
    "\n",
    "files = []\n",
    "for file in glob.glob(BNHTRD_DATASET+\"/114/Words/*/*.[jJ|pP][pP|nN][gG]\"):\n",
    "    files.append(file)\n",
    "files = set([Path(file).stem for file in files])\n",
    "\n",
    "files.difference(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'word'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108144"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "107351 + 793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNHTRD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "BNHTRD_DATASET = \"/home/ec2-user/word_level_ocr/sabbir/datasets/BN-HTRd/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnhtrdWordDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        file_paths = glob.glob(root_dir+\"/*/Words/*/*.[jJ|pP][pP|nN][gG]\")\n",
    "        self.file_name_to_path_dict = {Path(file_path).stem:file_path for file_path in file_paths}\n",
    "        \n",
    "        # for file_path in file_paths:\n",
    "        #     file_name = Path(file_path).stem\n",
    "        #     if re.match(r\"^[0-9]+_[0-9]+_[0-9]+_[0-9]+$\", file_name) is None:\n",
    "        #         print(file_name)\n",
    "        \n",
    "        self.label_dict = self._create_label_dict(root_dir)\n",
    "        self.file_name_list = list(self.label_dict.keys())\n",
    "        \n",
    "        self.inp_h = 32\n",
    "        self.inp_w = 128\n",
    "        self.transform = transform\n",
    "        \n",
    "    def _create_label_dict(self, root_dir):\n",
    "        \n",
    "        annotation_files = []\n",
    "        \n",
    "        for subdir in os.listdir(root_dir):\n",
    "            ann_file = glob.glob(root_dir+\"/\"+subdir+\"/*.xlsx\")\n",
    "            \n",
    "            if subdir == \"17\":\n",
    "                # 17.xlsx mistakenly has two sheets, and we need to specify which one to open\n",
    "                df = pd.read_excel(list(ann_file)[0], sheet_name=\"Sheet1\")\n",
    "            else:\n",
    "                df = pd.read_excel(list(ann_file)[0])\n",
    "\n",
    "            if subdir==\"101\":\n",
    "                # 101.xlsx has some trailing Nan value rows\n",
    "                df = df[df['Id'].notna()]\n",
    "            elif subdir==\"60\":\n",
    "                df = df.rename(columns={'ID': 'Id', 'word': 'Word'})\n",
    "            \n",
    "            annotation_files.append(df)\n",
    "        \n",
    "        merged_dataframe = pd.concat(annotation_files)\n",
    "        # Remove duplicate entries\n",
    "        merged_dataframe = merged_dataframe.drop_duplicates(subset='Id', keep=\"first\")\n",
    "        \n",
    "        merged_dict = dict(zip(merged_dataframe.Id, merged_dataframe.Word))\n",
    "        \n",
    "        # Some file names do not match with their equivalent in the excel files\n",
    "        # We ignore those files\n",
    "        cleaned_dict = {k:str(v) for (k, v) in merged_dict.items() if \\\n",
    "                        re.match(r\"^[0-9]+_[0-9]+_[0-9]+_[0-9]+$\", k) is not None \\\n",
    "                       and k in self.file_name_to_path_dict.keys()}\n",
    "        \n",
    "        return cleaned_dict\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_dict)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_name_list[idx]\n",
    "        file_path = self.file_name_to_path_dict[file_name]\n",
    "        \n",
    "        label = self.label_dict[file_name]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_h, img_w = image.shape\n",
    "        image = cv2.resize(image, (0,0), fx=self.inp_w / img_w, fy=self.inp_h / img_h, interpolation=cv2.INTER_CUBIC)\n",
    "        image = np.reshape(image, (self.inp_h, self.inp_w, 1))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)[\"image\"]\n",
    "            return image, file_name, idx\n",
    "        else:\n",
    "            image = image.transpose(2, 0, 1)\n",
    "            return image, label, idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnhtrd = BnhtrdWordDataset(BNHTRD_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108147"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = bnhtrd.file_name_to_path_dict\n",
    "len(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107090"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = bnhtrd.label_dict\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=\"সংসদ9\"\n",
    "lol = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\\u200d\\u200c\\n ©\"\n",
    "flag=True\n",
    "for i in v1:\n",
    "    if i in lol:\n",
    "        flag=False\n",
    "        break\n",
    "if flag:\n",
    "    print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copying? YES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107090/107090 [08:10<00:00, 218.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next train filename should start with id: 104504.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# not excluding space as some xlsx label files has space in them. space is removed afterwards using\n",
    "# strip. but this also makes empty labels which are then removed in mod_train and mod_val\n",
    "EXCLUDE_CLASSES = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\\u200d\\u200c\\n©\"\n",
    "#v1=সংসদ v2=path\n",
    "DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd/'\n",
    "if input(\"Start copying?\") == \"YES\":\n",
    "     with open(DESTINATION_PATH + \"all_labels.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "            id=0\n",
    "            for k1,v1 in tqdm(labels.items()):\n",
    "                take_word=True\n",
    "                for k2,v2 in file_path.items():\n",
    "                    if k1==k2:\n",
    "                        for i in v1:\n",
    "                            if i in EXCLUDE_CLASSES:\n",
    "                                take_word=False\n",
    "                                break\n",
    "                        if take_word:\n",
    "                            src=v2\n",
    "                            des_name = \"{}.jpg\".format(id)\n",
    "                            destn = DESTINATION_PATH + \"all/\" + des_name\n",
    "                            f.write(\"{} {}\\n\".format(des_name, v1.strip()))\n",
    "                            copyfile(src, destn)\n",
    "                            id=id+1\n",
    "                            break\n",
    "                        else:\n",
    "                            break\n",
    "            print(f\"Next train filename should start with id: {id}.jpg\")\n",
    "else:\n",
    "    print(\"Not copied\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83603, 20901, 104504)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd/'\n",
    "# with open(DESTINATION_PATH + \"all_labels.txt\", \"r\") as f:\n",
    "#     all_labels = f.readlines()\n",
    "\n",
    "# all_labels = [x.strip() for x in all_labels]\n",
    "# random.shuffle(all_labels)\n",
    "# train = all_labels[:round(0.8*len(all_labels))]\n",
    "# val = all_labels[-round(0.2*len(all_labels)):]\n",
    "# len(train), len(val), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101020.jpg প্রবৃদ্ধির'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[38194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83571"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train = []\n",
    "i=0\n",
    "for line in train:\n",
    "    n = line.split()\n",
    "    if not (len(n)<2 or len(n)>2):\n",
    "        mod_train.append(line) \n",
    "len(mod_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20898"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_val = []\n",
    "i=0\n",
    "for line in val:\n",
    "    n = line.split()\n",
    "    if not (len(n)<2 or len(n)>2):\n",
    "        mod_val.append(line) \n",
    "len(mod_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copying? YES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83571/83571 [00:19<00:00, 4202.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next train filename should start with id: 83571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "# BNHTRD_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd/'\n",
    "# if input(\"Start copying?\") == \"YES\":\n",
    "#     with open(DESTINATION_PATH + \"train_labels.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "#         id=0\n",
    "#         for line in tqdm(mod_train):\n",
    "#             src_name = line.split()[0]\n",
    "#             word = line.split()[1]\n",
    "#             src = BNHTRD_PATH  + \"all/\" + src_name\n",
    "#             des_name = \"{}.jpg\".format(id)\n",
    "#             destn = DESTINATION_PATH + \"train/\" + des_name\n",
    "#             f.write(\"{} {}\\n\".format(des_name, word))\n",
    "#             copyfile(src,destn)\n",
    "#             id=id+1\n",
    "#         print(f\"Next train filename should start with id: {id}.jpg\")\n",
    "# else:\n",
    "#     print(\"Not copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copying? YES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20898/20898 [00:01<00:00, 18585.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next train filename should start with id: 20898.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "# BNHTRD_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd/'\n",
    "# if input(\"Start copying?\") == \"YES\":\n",
    "#     with open(DESTINATION_PATH + \"valid_labels.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "#         id=0\n",
    "#         for line in tqdm(mod_val):\n",
    "#             src_name = line.split()[0]\n",
    "#             word = line.split()[1]\n",
    "#             src = BNHTRD_PATH  + \"all/\" + src_name\n",
    "#             des_name = \"{}.jpg\".format(id)\n",
    "#             destn = DESTINATION_PATH + \"valid/\" + des_name\n",
    "#             f.write(\"{} {}\\n\".format(des_name, word))\n",
    "#             copyfile(src,destn)\n",
    "#             id=id+1\n",
    "#         print(f\"Next train filename should start with id: {id}.jpg\")\n",
    "# else:\n",
    "#     print(\"Not copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83571, 20898)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "with open(DESTINATION_PATH + \"train_labels.txt\", \"r\") as f:\n",
    "    train_labels = f.readlines()\n",
    "train_labels = [x.strip() for x in train_labels]\n",
    "\n",
    "DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "with open(DESTINATION_PATH + \"valid_labels.txt\", \"r\") as f:\n",
    "    valid_labels = f.readlines()\n",
    "valid_labels = [x.strip() for x in valid_labels]\n",
    "\n",
    "len(train_labels), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copying? YES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83571/83571 [00:04<00:00, 18465.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next train filename should start with id: 83571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_all/'\n",
    "BNHTRD_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "if input(\"Start copying?\") == \"YES\":\n",
    "    with open(DESTINATION_PATH + \"all_labels.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "        id=0\n",
    "        for line in tqdm(train_labels):\n",
    "            src_name = line.split()[0]\n",
    "            word = line.split()[1]\n",
    "            src = BNHTRD_PATH  + \"train/\" + src_name\n",
    "            des_name = \"{}.jpg\".format(id)\n",
    "            destn = DESTINATION_PATH + \"all/\" + des_name\n",
    "            f.write(\"{} {}\\n\".format(des_name, word))\n",
    "            copyfile(src,destn)\n",
    "            id=id+1\n",
    "        print(f\"Next train filename should start with id: {id}.jpg\")\n",
    "else:\n",
    "    print(\"Not copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start copying? YES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20898/20898 [00:01<00:00, 18342.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next train filename should start with id: 104469.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_all/'\n",
    "BNHTRD_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "if input(\"Start copying?\") == \"YES\":\n",
    "    with open(DESTINATION_PATH + \"all_labels.txt\", \"a\", encoding=\"utf8\") as f:\n",
    "        id=83571\n",
    "        for line in tqdm(valid_labels):\n",
    "            src_name = line.split()[0]\n",
    "            word = line.split()[1]\n",
    "            src = BNHTRD_PATH  + \"valid/\" + src_name\n",
    "            des_name = \"{}.jpg\".format(id)\n",
    "            destn = DESTINATION_PATH + \"all/\" + des_name\n",
    "            f.write(\"{} {}\\n\".format(des_name, word))\n",
    "            copyfile(src,destn)\n",
    "            id=id+1\n",
    "        print(f\"Next train filename should start with id: {id}.jpg\")\n",
    "else:\n",
    "    print(\"Not copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104469"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_all/'\n",
    "with open(DESTINATION_PATH + \"all_labels.txt\", \"r\") as f:\n",
    "    all_labels = f.readlines()\n",
    "all_labels = [x.strip() for x in all_labels]\n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83571"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DESTINATION_PATH = '/home/ec2-user/word_level_ocr/rakib/datasets/bnhtrd_train_val/'\n",
    "# a = glob.glob(DESTINATION_PATH + \"train/*.jpg\")\n",
    "# # import os\n",
    "# # a = sorted(os.listdir(DESTINATION_PATH + \"train/\"))\n",
    "# # for i in a:\n",
    "# #     print(i)\n",
    "# #     print(int(i.split('.')[0]))\n",
    "# # # b = sorted(a, key=lambda x: int(x.split('.')[0]))\n",
    "# len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[224, 224, 224, ..., 223, 225, 225],\n",
       "        [224, 224, 224, ..., 223, 224, 224],\n",
       "        [224, 224, 224, ..., 224, 224, 224],\n",
       "        ...,\n",
       "        [223, 223, 223, ..., 224, 224, 224],\n",
       "        [224, 224, 224, ..., 222, 224, 225],\n",
       "        [224, 224, 224, ..., 225, 224, 222]]], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnhtrd[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(bnhtrd[0][0][0], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107090"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors=0\n",
    "for i in range(len(bnhtrd)):\n",
    "    errors+=1\n",
    "    data=bnhtrd[i]\n",
    "\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating character labels in the usable images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_word(word):\n",
    "\n",
    "    if 'ো' in word: word = word.replace('ো', 'ো')\n",
    "    \n",
    "    if 'ৗ' in word:    \n",
    "        if 'ৌ' in word: word = word.replace('ৌ', 'ৌ') \n",
    "        else: word = word.replace('ৗ', 'ী') # 'ৗ' without 'ে' is replaced by 'ী'\n",
    "    \n",
    "    if '়' in word:\n",
    "        if 'ব়' in word: word = word.replace('ব়', 'র')\n",
    "        if 'য়' in word: word = word.replace('য়', 'য়')\n",
    "        if 'ড়' in word: word = word.replace('ড়', 'ড়')\n",
    "        if 'ঢ়' in word: word = word.replace('ঢ়', 'ঢ়')\n",
    "        if '়' in word: word = word.replace('়', '') # discard any other '়' without 'ব'/'য'/'ড'/'ঢ'\n",
    "        \n",
    "    # visually similar '৷' (Bengali Currency Numerator Four) is replaced by '।' (Devanagari Danda)\n",
    "    if '৷' in word: word = word.replace('৷', '।')\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Consonant Clusters Intact\n",
    "def extract_graphemes(word):\n",
    "    \n",
    "    forms_cluster = {'ক': ['ক', 'ট', 'ত', 'ন', 'ব', 'ম', 'র', 'ল', 'ষ', 'স'],\n",
    "                     'গ': ['গ', 'ধ', 'ন', 'ব', 'ম', 'ল'],\n",
    "                     'ঘ': ['ন'],\n",
    "                     'ঙ': ['ক', 'খ', 'গ', 'ঘ', 'ম'],\n",
    "                     'চ': ['চ', 'ছ', 'ঞ'],\n",
    "                     'জ': ['জ', 'ঝ', 'ঞ', 'ব'],\n",
    "                     'ঞ': ['চ', 'ছ', 'জ', 'ঝ'],\n",
    "                     'ট': ['ট', 'ব'],\n",
    "                     'ড': ['ড'],\n",
    "                     'ণ': ['ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ব', 'ম'],\n",
    "                     'ত': ['ত', 'থ', 'ন', 'ব', 'ম', 'র'],\n",
    "                     'থ': ['ব'],\n",
    "                     'দ': ['গ', 'ঘ', 'দ', 'ধ', 'ব', 'ভ', 'ম'],\n",
    "                     'ধ': ['ন', 'ব'],\n",
    "                     'ন': ['জ', 'ট', 'ঠ', 'ড', 'ত', 'থ', 'দ', 'ধ', 'ন', 'ব', 'ম', 'স'],\n",
    "                     'প': ['ট', 'ত', 'ন', 'প', 'ল', 'স'],\n",
    "                     'ফ': ['ট', 'ল'],\n",
    "                     'ব': ['জ', 'দ', 'ধ', 'ব', 'ভ', 'ল'],\n",
    "                     'ভ': ['র'],\n",
    "                     'ম': ['ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'ল'],\n",
    "                     'ল': ['ক', 'গ', 'ট', 'ড', 'প', 'ফ', 'ব', 'ম', 'ল', 'স'],\n",
    "                     'শ': ['চ', 'ছ', 'ত', 'ন', 'ব', 'ম', 'ল'],\n",
    "                     'ষ': ['ক', 'ট', 'ঠ', 'ণ', 'প', 'ফ', 'ব', 'ম'],\n",
    "                     'স': ['ক', 'খ', 'ট', 'ত', 'থ', 'ন', 'প', 'ফ', 'ব', 'ম', 'ল'],\n",
    "                     'হ': ['ণ', 'ন', 'ব', 'ম', 'ল'],\n",
    "                     'ড়': ['গ']}\n",
    "    \n",
    "    forms_tripple_cluster = {'ক্ষ': ['ণ', 'ম'], 'ঙ্ক': ['ষ'], 'চ্ছ': ['ব'], 'জ্জ': ['ব'],\n",
    "                             'ত্ত': ['ব'], 'দ্দ': ['ব'], 'দ্ধ': ['ব'], 'দ্ভ': ['র'],\n",
    "                             'ন্ত': ['ব'], 'ন্দ': ['ব'], 'ম্প': ['ল'], 'ম্ভ': ['র'],\n",
    "                             'ষ্ক': ['র'], 'স্ক': ['র'], 'স্ত': ['ব', 'র'], 'স্প': ['ল']}\n",
    "    \n",
    "    chars = []\n",
    "    i = 0\n",
    "    adjust = 0\n",
    "    \n",
    "    while(i < len(word)):\n",
    "        if i+1 < len(word) and word[i+1] == '্':\n",
    "            if word[i] == 'র':\n",
    "                chars.append('র্')\n",
    "                adjust = 0\n",
    "                i+=2\n",
    "            elif i+2 < len(word) and word[i+2] == 'য':\n",
    "                chars.append(word[i-adjust:i+1])\n",
    "                chars.append('্য')\n",
    "                adjust = 0\n",
    "                i+=3\n",
    "            elif i+2 < len(word) and word[i+2] == 'র':\n",
    "                # Treat '্র' as a seperate grapheme\n",
    "                chars.append(word[i-adjust:i+1])\n",
    "                chars.append('্র')\n",
    "                # Keep '্র' icluded in the cluster\n",
    "                # chars.append(word[i-adjust:i+3])\n",
    "                if i+3 < len(word) and word[i+3] == '্' and i+4 < len(word) and word[i+4] == 'য':    \n",
    "                    chars.append('্য')\n",
    "                    i+=5\n",
    "                else:\n",
    "                    i+=3\n",
    "                adjust = 0\n",
    "            elif i+2 < len(word) and adjust!=0 and word[i-adjust:i+1] in forms_tripple_cluster \\\n",
    "                and word[i+2] in forms_tripple_cluster[word[i-adjust:i+1]]:\n",
    "                if i+3 < len(word) and word[i+3] == '্':\n",
    "                    adjust += 2\n",
    "                    i+=2\n",
    "                else:\n",
    "                    chars.append(word[i-adjust:i+3])\n",
    "                    adjust = 0\n",
    "                    i+=3\n",
    "            elif i+2 < len(word) and adjust==0 and word[i] in forms_cluster and word[i+2] in forms_cluster[word[i]]:\n",
    "                if i+3 < len(word) and word[i+3] == '্':\n",
    "                    adjust += 2\n",
    "                    i+=2\n",
    "                else:\n",
    "                    chars.append(word[i-adjust:i+3])\n",
    "                    adjust = 0\n",
    "                    i+=3\n",
    "            else:\n",
    "                chars.append(word[i-adjust:i+1])\n",
    "                chars.append('্')\n",
    "                adjust = 0\n",
    "                i+=2\n",
    "\n",
    "        else:\n",
    "            chars.append(word[i:i+1])\n",
    "            i+=1\n",
    "\n",
    "    \n",
    "    #print(word)\n",
    "    #print(chars)\n",
    "\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnhtrd = BnhtrdWordDataset(BNHTRD_DATASET)\n",
    "label_dict = bnhtrd.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ণ্ঠ', 'ূ', 'ক্ত', 'আ', 'ব্ল', 'গ্ধ', 'ত্থ', 'া', 'প্ল', 'দ্ম', 'স্ল', 'f', 'ৈ', 'ম্ন', 'ক্ক', 'ণ্ট', 'ঋ', 'গ', 'ত', '—', '•', 'ঙ্খ', 'b', 'ড', 'জ্ব', 'ক', 'k', 'ঙ্ক্ষ', '্', '7', 'ক্ষ', '·', 'ত্ম', 'J', 'হ্ণ', 'গ্ল', 'K', 'A', 'ষ্ক', 'g', 'F', 'ত্ত', 'ধ', '[', 'প্প', 'ড়', 'ষ্ট', 'O', 'ঞ্জ', 'ত্ন', 'ম্ল', 'M', '“', '8', 'ন', '২', 'ক্ন', 'ঃ', 'শ্ব', 'শ্চ', 'ঢ', 'স্ব', 'U', '৮', 'ল্ল', '\\u200c', 'ড্ড', 'D', 'স্ন', 'হ্ব', 'S', 'ষ্ণ', 'ম্ম', '&', 'চ', 'ল্প', 'ধ্ব', 'd', 'ৌ', 'স্থ', '©', '\\u200d', 'ল্ফ', 't', 'ন্ড', 'w', 'উ', 'ঢ়', 'ক্ল', '@', 'হ্ন', 'ন্ন', 'স্ম', 'ট্ট', 'স্ত', 'ল্ড', 'ু', 'ব্ধ', '|', 'ন্স', 'প', 'ষ্প', 'R', 'P', 'ভ', '–', '+', ']', 'ল্ট', 'ণ', 'ছ', 'ক্স', 'ে', 'ন্ব', 'ঈ', 'ঊ', 'ত্ব', '1', 'জ', 'ী', 'I', 'খ', '5', 'ণ্ড', 'ফ্ল', 'ং', 'ঘ্ন', 'প্ত', ',', 'দ্ভ', ':', 'স্প', 'H', 'z', 'ও', 'N', 'ৎ', 'C', 'ঙ্গ', 'm', '3', 'ম্ভ', 'ষ্ম', 'হ্ম', '”', 'ঠ', 'স্ট', 'G', 'ণ্ণ', 'অ', 'ন্ম', 'B', '?', 'ঘ', 'ন্দ্ব', 'জ্জ', 'ঙ', 'ব', '৭', 'ম্ব', '/', 'ি', 'ো', 'শ্ল', 'প্ন', 'শ্ম', 'Q', '*', 'ষ্ঠ', '\"', 'a', '৪', 'ক্ষ্ম', 'দ', '১', 'ব্দ', 'ঔ', 'ন্ত', 'X', 'র', 'y', 'ঝ', 'স্ক', 'জ্ঞ', 'ঙ্ক', 'ম্ফ', \"'\", 'স্ফ', 'শ', 'ৃ', '%', '\\n', '4', 'e', 'চ্চ', 'l', 'c', 'ট', 'দ্ধ', 'u', 's', 'Z', 'v', '’', 'ন্ট', 'o', 'i', '0', 'গ্ম', '।', 'ল', 'ন্থ', ';', 'ক্ষ্ণ', 'হ', 'n', 'য', 'জ্জ্ব', 'র্', 'দ্ব', '.', '_', 'p', 'ঞ্চ', '‘', 'ত্ত্ব', 'ব্ব', '্য', 'স', '6', '৬', 'দ্দ', 'য়', 'r', 'থ', '৩', 'x', '৯', 'Y', 'ঐ', 'চ্ছ', '৫', 'চ্ছ্ব', 'শ্ন', '2', 'ষ', ')', '০', ' ', 'ঁ', 'W', 'T', 'প্ট', 'V', '-', 'ঞ', 'L', 'ম্প', 'ম', '!', 'গ্ন', 'ই', 'ল্ক', 'ফ', '#', 'ন্ধ', 'ব্জ', '9', 'E', '্র', 'ক্ট', 'h', '(', 'ন্দ', 'এ'}\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "grapheme_set = set()\n",
    "\n",
    "for file_name, label in label_dict.items():\n",
    "    # print(label, type(label))\n",
    "    graphemes_in_label = extract_graphemes(normalize_word(label))\n",
    "    grapheme_set = grapheme_set.union(graphemes_in_label)\n",
    "    \n",
    "print(grapheme_set)\n",
    "print(len(grapheme_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('া', 50414), (' ', 48871), ('ে', 44887), ('র', 32625), ('ি', 28282), ('ন', 22238), ('ক', 20532), ('ব', 18634), ('ত', 13679), ('স', 13004), ('ল', 12866), ('ম', 11367), ('য়', 9981), ('প', 9802), ('দ', 8488), ('ু', 8141), ('ো', 6816), ('হ', 6790), ('।', 6060), ('ই', 6040), ('শ', 5909), ('ট', 5807), ('্র', 5634), ('জ', 5621), ('্য', 5513), ('এ', 5263), ('ছ', 5195), ('আ', 4904), ('গ', 4495), ('ী', 4355), ('ভ', 4185), ('র্', 3999), ('য', 3630), ('ং', 3302), ('চ', 3286), (',', 3276), ('খ', 3125), ('ও', 2975), ('থ', 2821), ('অ', 2628), ('ধ', 2331), ('উ', 1875), ('ণ', 1871), ('ড়', 1661), ('ফ', 1514), ('ষ', 1466), ('ন্ত', 1419), ('ক্ষ', 1390), ('-', 1242), ('ড', 1204), ('1', 977), ('0', 932), ('\"', 912), ('স্থ', 819), ('ৃ', 803), ('2', 799), ('ূ', 745), ('ঠ', 689), ('শ্ব', 669), ('ঁ', 594), ('ক্ত', 592), ('ন্দ', 576), ('চ্ছ', 563), ('ঘ', 554), (\"'\", 549), ('ৈ', 498), ('ষ্ট', 490), ('স্ট', 488), ('ৎ', 486), ('স্ত', 480), ('ঙ্গ', 457), (':', 452), ('স্ব', 437), ('দ্ধ', 418), ('9', 418), ('ম্প', 394), ('?', 393), ('ন্ড', 382), ('e', 371), ('ন্ট', 371), ('5', 313), ('ষ্ঠ', 285), ('.', 265), ('8', 260), ('4', 259), ('t', 253), ('ত্ব', 253), ('ৌ', 245), ('জ্ঞ', 243), ('s', 241), ('3', 240), ('B', 239), ('ন্ন', 237), ('ত্ত', 220), ('স্ক', 216), ('ন্ধ', 212), ('১', 210), ('7', 208), ('ঝ', 205), ('6', 205), ('ম্ব', 178), ('ল্প', 173), ('a', 168), ('দ্ব', 163), ('ঢ', 161), ('স্প', 160), ('ন্স', 154), ('I', 154), ('২', 153), ('N', 153), ('C', 138), ('ল্ল', 137), ('w', 131), ('দ্দ', 126), ('ম্ভ', 124), ('চ্চ', 119), ('ঙ্ক', 116), ('ঞ্জ', 107), ('শ্চ', 100), ('y', 100), ('শ্ন', 96), ('g', 95), ('ক্স', 95), ('m', 95), ('n', 95), ('(', 95), ('ঙ', 94), (')', 94), ('G', 92), ('ম্ম', 91), ('ট্ট', 91), ('প্ত', 91), ('A', 86), ('ত্ম', 83), ('o', 82), ('০', 81), ('ঞ্চ', 79), ('ঐ', 78), ('“', 71), ('r', 70), ('ণ্ড', 69), ('i', 69), ('ফ্ল', 64), ('ম্ন', 59), ('h', 56), ('ব্ব', 55), ('ক্ল', 54), ('ষ্ক', 53), ('৯', 53), ('©', 51), ('৫', 50), ('৬', 49), ('S', 48), ('R', 48), ('প্ল', 46), ('ল্ড', 46), ('ন্ম', 46), ('৩', 46), ('ঃ', 45), ('\\n', 45), ('l', 45), ('শ্ল', 43), ('ব্ল', 42), ('D', 41), ('u', 41), ('জ্জ', 40), ('৪', 39), ('ঔ', 39), ('ক্ট', 39), ('T', 38), ('৮', 37), ('ত্ত্ব', 36), ('‘', 35), ('জ্ব', 34), ('O', 34), ('•', 33), ('ধ্ব', 33), ('৭', 33), ('H', 32), ('ব্দ', 32), ('E', 32), ('K', 30), ('\\u200d', 30), ('’', 30), ('ষ্ণ', 29), ('ল্ট', 27), ('p', 27), ('M', 26), ('d', 26), ('ন্থ', 26), ('স্ম', 24), ('P', 24), ('c', 24), ('গ্ল', 23), ('|', 23), ('ত্থ', 21), ('ণ্ট', 21), ('ঈ', 21), ('দ্ভ', 21), ('ন্দ্ব', 21), ('ক্ক', 20), ('্', 20), ('গ্ন', 20), ('U', 18), ('ন্ব', 18), ('/', 18), ('f', 17), ('ঙ্খ', 17), ('Y', 17), ('W', 17), ('L', 17), ('ঋ', 15), ('F', 15), ('ক্ষ্ম', 14), ('প্ট', 14), ('Z', 13), ('ত্ন', 12), ('\\u200c', 12), ('হ্ব', 12), ('%', 12), ('b', 11), ('k', 10), ('!', 10), ('স্ল', 9), ('ঙ্ক্ষ', 9), ('হ্ন', 9), ('”', 9), ('–', 8), ('ঊ', 8), ('v', 8), ('স্ন', 7), ('ঢ়', 7), ('ব্ধ', 7), ('ড্ড', 6), ('প্ন', 6), ('V', 6), ('#', 6), ('ণ্ঠ', 5), ('দ্ম', 5), ('ষ্ম', 5), ('J', 4), ('ষ্প', 4), ('ঘ্ন', 4), ('গ্ধ', 3), ('—', 3), ('প্প', 3), ('&', 3), ('ল্ফ', 3), ('X', 3), ('স্ফ', 3), ('গ্ম', 3), (';', 3), ('x', 3), ('·', 2), ('হ্ণ', 2), ('[', 2), ('ম্ল', 2), ('@', 2), ('+', 2), (']', 2), ('শ্ম', 2), ('*', 2), ('ক্ষ্ণ', 2), ('জ্জ্ব', 2), ('_', 2), ('ল্ক', 2), ('ক্ন', 1), ('z', 1), ('হ্ম', 1), ('ণ্ণ', 1), ('Q', 1), ('ম্ফ', 1), ('চ্ছ্ব', 1), ('ঞ', 1), ('ব্জ', 1)]\n"
     ]
    }
   ],
   "source": [
    "graphemes_count_dict = {k:0 for k in grapheme_set}\n",
    "\n",
    "for file_name, label in label_dict.items():\n",
    "    # print(label, type(label))\n",
    "    graphemes_in_label = extract_graphemes(normalize_word(label))\n",
    "    for grapheme in graphemes_in_label:\n",
    "        graphemes_count_dict[grapheme] += 1\n",
    "        \n",
    "graphemes_count_dict\n",
    "\n",
    "print(sorted([(k,v) for k,v in graphemes_count_dict.items()], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ণ্ঠ', 'ূ', 'ক্ত', 'আ', 'ব্ল', 'গ্ধ', 'ত্থ', 'া', 'প্ল', 'দ্ম', 'স্ল', 'ৈ', 'ম্ন', 'ক্ক', 'ণ্ট', 'ঋ', 'গ', 'ত', '—', '•', 'ঙ্খ', 'ড', 'জ্ব', 'ক', 'ঙ্ক্ষ', '্', 'ক্ষ', '·', 'ত্ম', 'হ্ণ', 'গ্ল', 'ষ্ক', 'ত্ত', 'ধ', '[', 'প্প', 'ড়', 'ষ্ট', 'ঞ্জ', 'ত্ন', 'ম্ল', '“', 'ন', '২', 'ক্ন', 'ঃ', 'শ্ব', 'শ্চ', 'ঢ', 'স্ব', '৮', 'ল্ল', 'ড্ড', 'স্ন', 'হ্ব', 'ষ্ণ', 'ম্ম', '&', 'চ', 'ল্প', 'ধ্ব', 'ৌ', 'স্থ', '\\u200d', 'ল্ফ', 'ন্ড', 'উ', 'ঢ়', 'ক্ল', '@', 'হ্ন', 'ন্ন', 'স্ম', 'ট্ট', 'স্ত', 'ল্ড', 'ু', 'ব্ধ', '|', 'ন্স', 'প', 'ষ্প', 'ভ', '–', '+', ']', 'ল্ট', 'ণ', 'ছ', 'ক্স', 'ে', 'ন্ব', 'ঈ', 'ঊ', 'ত্ব', 'জ', 'ী', 'খ', 'ণ্ড', 'ফ্ল', 'ং', 'ঘ্ন', 'প্ত', ',', 'দ্ভ', ':', 'স্প', 'ও', 'ৎ', 'ঙ্গ', 'ম্ভ', 'ষ্ম', 'হ্ম', '”', 'ঠ', 'স্ট', 'ণ্ণ', 'অ', 'ন্ম', '?', 'ঘ', 'ন্দ্ব', 'জ্জ', 'ঙ', 'ব', '৭', 'ম্ব', '/', 'ি', 'ো', 'শ্ল', 'প্ন', 'শ্ম', '*', 'ষ্ঠ', '\"', '৪', 'ক্ষ্ম', 'দ', '১', 'ব্দ', 'ঔ', 'ন্ত', 'র', 'ঝ', 'স্ক', 'জ্ঞ', 'ঙ্ক', 'ম্ফ', \"'\", 'স্ফ', 'শ', 'ৃ', '%', 'চ্চ', 'ট', 'দ্ধ', '’', 'ন্ট', 'গ্ম', '।', 'ল', 'ন্থ', ';', 'ক্ষ্ণ', 'হ', 'য', 'জ্জ্ব', 'র্', 'দ্ব', '.', '_', 'ঞ্চ', '‘', 'ত্ত্ব', 'ব্ব', '্য', 'স', '৬', 'দ্দ', 'য়', 'থ', '৩', '৯', 'ঐ', 'চ্ছ', '৫', 'চ্ছ্ব', 'শ্ন', 'ষ', ')', '০', 'ঁ', 'প্ট', '-', 'ঞ', 'ম্প', 'ম', '!', 'গ্ন', 'ই', 'ল্ক', 'ফ', '#', 'ন্ধ', 'ব্জ', '্র', 'ক্ট', '(', 'ন্দ', 'এ'}\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "EXCLUDE_CLASSES = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\\u200d\\u200c\\n ©\"\n",
    "\n",
    "after_exclusion = grapheme_set.difference(EXCLUDE_CLASSES)\n",
    "print(after_exclusion)\n",
    "print(len(after_exclusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['অ', 'ব', 'স্থ', 'া', ' ', '\\n']\n"
     ]
    }
   ],
   "source": [
    "for file_name, label in label_dict.items():\n",
    "    graphemes_in_label = extract_graphemes(normalize_word(label))\n",
    "    if \"\\n\" in graphemes_in_label:\n",
    "        print(graphemes_in_label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"০\"==\"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10 (default, Jun  3 2021, 00:02:01) \n[GCC 7.3.1 20180712 (Red Hat 7.3.1-13)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
