{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MJSynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MJSynthDataset(data.Dataset):\n",
    "    def __init__(self, img_dir, annotation_file, transform=None):\n",
    "\n",
    "#         self.s_img_dir = '/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/MJSYNTH/mnt/ramdisk/max/90kDICT32px/'\n",
    "        self.s_img_dir = img_dir\n",
    "        self.inp_h = 32\n",
    "        self.inp_w = 128\n",
    "        self.mean = np.array(0.588, dtype=np.float32)\n",
    "        self.std = np.array(0.193, dtype=np.float32)\n",
    "        \n",
    "#         mjsynth_annotation_file = '/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/MJSYNTH/mnt/ramdisk/max/90kDICT32px/annotation_train.txt'\n",
    "        mjsynth_annotation_file = annotation_file\n",
    "\n",
    "        with open(mjsynth_annotation_file, 'r') as file:\n",
    "            s_images = file.readlines()\n",
    "        self.s_images = sorted(s_images)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.s_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # for training data (synthetic)\n",
    "        try:\n",
    "            img_name = self.s_images[idx].split(' ')[0].split('./')[1]\n",
    "            image = cv2.imread(os.path.join(self.s_img_dir, img_name))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        except:\n",
    "            img_name = self.s_images[idx-1].split(' ')[0].split('./')[1] #random to avoid error\n",
    "            image = cv2.imread(os.path.join(self.s_img_dir, img_name))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "\n",
    "        image = cv2.resize(image, (0,0), fx=self.inp_w / img_w, fy=self.inp_h / img_h, interpolation=cv2.INTER_CUBIC)\n",
    "        image = np.reshape(image, (self.inp_h, self.inp_w, 1))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)[\"image\"]#[\"image\"]\n",
    "            return image, img_name, idx\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        \n",
    "        \n",
    "        return image, img_name, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IIIT5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sio.loadmat(\"/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/IIIT5K/traindata.mat\")\n",
    "test_data = sio.loadmat(\"/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/IIIT5K/testdata.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_data['traindata'][0]))\n",
    "print(len(test_data['testdata'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_data['traindata'][0]\n",
    "print(images[1][0][0])\n",
    "print(images[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IIIT5kDataset(data.Dataset):\n",
    "    def __init__(self, img_dir, annotation_file, train=True, transform=None):\n",
    "\n",
    "#         self.s_img_dir = '/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/MJSYNTH/mnt/ramdisk/max/90kDICT32px/'\n",
    "        self.img_dir = img_dir\n",
    "        self.inp_h = 32\n",
    "        self.inp_w = 128\n",
    "        self.mean = np.array(0.588, dtype=np.float32)\n",
    "        self.std = np.array(0.193, dtype=np.float32)\n",
    "        \n",
    "#         mjsynth_annotation_file = '/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/MJSYNTH/mnt/ramdisk/max/90kDICT32px/annotation_train.txt'\n",
    "        iiit5k_annotation_file = annotation_file\n",
    "        data = sio.loadmat(iiit5k_annotation_file)\n",
    "        \n",
    "        if train:\n",
    "            self.images = data['traindata'][0]\n",
    "        else:\n",
    "            self.images = data['testdata'][0]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_name = self.images[idx][0][0]\n",
    "        image = cv2.imread(os.path.join(self.img_dir, img_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_h, img_w = image.shape\n",
    "        image = cv2.resize(image, (0,0), fx=self.inp_w / img_w, fy=self.inp_h / img_h, interpolation=cv2.INTER_CUBIC)\n",
    "        image = np.reshape(image, (self.inp_h, self.inp_w, 1))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)[\"image\"]#[\"image\"]\n",
    "            return image, img_name, idx\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        \n",
    "        \n",
    "        return image, img_name, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = \"/home/ec2-user/word_level_ocr/pritom/datasets/out_50000_Synthetic_controlled_12lakh\"\n",
    "# img_dir = '/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/MJSYNTH/mnt/ramdisk/max/90kDICT32px/'\n",
    "img_dir = '/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/IIIT5K/'\n",
    "\n",
    "# annotation_file = img_dir + 'annotation_train.txt'\n",
    "annotation_file = img_dir + 'traindata.mat'\n",
    "\n",
    "#Batch Size variable\n",
    "train_batch_s = 1\n",
    "valid_batch_s = 1\n",
    "\n",
    "##Albumentations noise\n",
    "data_transform = A.Compose([\n",
    "        A.augmentations.transforms.GaussNoise(var_limit=(120.0, 135.0), mean=0, always_apply=False,p=0.5),\n",
    "        A.imgaug.transforms.IAAAdditiveGaussianNoise(loc=1, scale=(2.5500000000000003, 12.75), per_channel=False, always_apply=False, p=0.5),\n",
    "        A.augmentations.transforms.MotionBlur(p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "# ocr_dataset = OCRDataset(img_dir, transform=data_transform)\n",
    "# ocr_dataset = MJSynthDataset(img_dir=img_dir, annotation_file=annotation_file, transform=None)\n",
    "ocr_dataset = IIIT5kDataset(img_dir=img_dir, annotation_file=annotation_file, transform=None)\n",
    "\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits\n",
    "validation_split = .15\n",
    "shuffle_dataset = True\n",
    "dataset_size = len(ocr_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= train_batch_s, \n",
    "                                           sampler=train_sampler, num_workers = 4)\n",
    "validation_loader = torch.utils.data.DataLoader(ocr_dataset, batch_size= valid_batch_s,\n",
    "                                                sampler=valid_sampler, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_to_plot = 20\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "for i, batch in enumerate(train_loader, start=1):\n",
    "    image, label, _ = batch\n",
    "    plt.subplot(10,10,i)\n",
    "    plt.imshow(image[0].reshape(32,128), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(label, fontsize=24)\n",
    "    if (i >= how_many_to_plot): break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVT (Create Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 49.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "data_dir = \"/home/ec2-user/word_level_ocr/computer/datasets/S2S_data/svt1/\"\n",
    "infile=open(os.path.join(data_dir, \"train.xml\"), \"r\")\n",
    "# infile=open(os.path.join(data_dir, \"test.xml\"), \"r\")\n",
    "\n",
    "extracted = \"extracted/train/\"\n",
    "# extracted = \"extracted/test/\"\n",
    "\n",
    "try:\n",
    "    # Create  Directory  MyDirectory \n",
    "    os.makedirs(os.path.join(data_dir, extracted))\n",
    "except FileExistsError:\n",
    "    ##print if directory already exists\n",
    "    print(\"Directory already exists.\")\n",
    "        \n",
    "contents = infile.read()\n",
    "soup = BeautifulSoup(contents,'xml')\n",
    "img_names = soup.find_all('imageName')\n",
    "count = 0\n",
    "\n",
    "for name in tqdm(img_names):\n",
    "        \n",
    "    #print(name)\n",
    "    image_path = os.path.join(data_dir, name.text)\n",
    "    #print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    # display(Image.fromarray(image))\n",
    "    words = name.find_next_sibling(\"taggedRectangles\").find_all(\"taggedRectangle\")\n",
    "    for word in words:\n",
    "        #print(str(word))\n",
    "        x = int(word[\"x\"])\n",
    "        y = int(word[\"y\"])\n",
    "        h = int(word[\"height\"])\n",
    "        w = int(word[\"width\"])\n",
    "        \n",
    "        word_img = image[y:h+y, x:x+w]\n",
    "        #display(Image.fromarray(word_img))\n",
    "        word_name = word.find_next(\"tag\").text\n",
    "        #print(word_name)\n",
    "        \n",
    "        if word_img.shape[0] == 0 or word_img.shape[1] == 0:\n",
    "            continue\n",
    "            \n",
    "        cv2.imwrite(os.path.join(data_dir, extracted, str(count) + \"_\" + word_name + \".jpg\"), word_img)\n",
    "        \n",
    "        count+=1\n",
    "\n",
    "# l = soup.tagset()\n",
    "# l[0].get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
